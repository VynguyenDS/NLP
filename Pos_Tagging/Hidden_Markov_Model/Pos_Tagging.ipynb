{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195795"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "vi_train = pd.read_table(\"vi_train.pos\", header = None )\n",
    "vi_train.columns = ['train_tagged_words']\n",
    "vi_train_tagged_words = [ tuple(tag_words.split('/')) for pair in vi_train['train_tagged_words'] for tag_words in pair.split() ]\n",
    "len(vi_train_tagged_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195517"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proprocessing of language\n",
    "tagged_words_processing = []\n",
    "for tag_words in vi_train_tagged_words:\n",
    "    #  add tag_words have length =2 tagged_words_processing\n",
    "    if len(tag_words) == 2:\n",
    "        tagged_words_processing.append(tag_words)\n",
    "len(tagged_words_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 53 is length 3\n",
    "# 227 is length <= 1 \n",
    "# 195515 is length = 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags, vocalb in corpus have unique\n",
    "tags = {tag for word,tag in tagged_words_processing}\n",
    "vocab = {word for word,tag in tagged_words_processing}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9011119e-01 1.5696534e-04 8.1883585e-03 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.7423153e-02]\n",
      " [8.4745765e-02 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [7.2941177e-02 0.0000000e+00 2.7450981e-02 ... 0.0000000e+00\n",
      "  0.0000000e+00 8.6274510e-03]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [2.4104235e-01 1.3029316e-04 4.2996742e-03 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.3811075e-02]]\n"
     ]
    }
   ],
   "source": [
    "# caculate emision probability\n",
    "def word_given_tag(word, tag, train_bag = tagged_words_processing):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "     # count tags\n",
    "    word_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    #now calculate the total number of times the passed word occurred as the passed tag.\n",
    "    count_w_given_tag = len(word_given_tag_list)\n",
    "    return (count_w_given_tag, count_tag)\n",
    "\n",
    "# caculate transition probability\n",
    "def transition_probability(t2, t1, train_bag = tagged_words_processing):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    \n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)\n",
    "trainsion_matrix_table = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for row, t1 in enumerate(list(tags)):\n",
    "    for column, t2 in enumerate(list(tags)): \n",
    "        trainsion_matrix_table[row, column] = transition_probability(t2, t1)[0]/transition_probability(t2, t1)[1]\n",
    " \n",
    "print(trainsion_matrix_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051262435"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainsion_matrix_table = pd.DataFrame(trainsion_matrix_table, columns = list(tags), index=list(tags))\n",
    "# display(trainsion_matrix_table)\n",
    "# store in trainsion_matrix_table \n",
    "trainsion_matrix_table.loc['-','Nc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viterbiAlgorithm is dynamic programming\n",
    "# It will be find the best probability each node to create setences\n",
    "def viterbiAlgorithm(words, train_bag = tagged_words_processing):\n",
    "    state = []\n",
    "    tag_corpus = list(set([pair[1] for pair in train_bag]))\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in tag_corpus:\n",
    "            if key == 0:\n",
    "                transition_probability = trainsion_matrix_table.loc['.', tag]\n",
    "            else:\n",
    "      \n",
    "                transition_probability = trainsion_matrix_table.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and state probabilities\n",
    "            emission_probability = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            \n",
    "            state_probability = emission_probability * transition_probability  \n",
    "          \n",
    "            p.append(state_probability)\n",
    "        # getting state for which probability is maximum\n",
    "        pmax = max(p)\n",
    "        state_max = tag_corpus[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file test\n",
    "vi_test = pd.read_table(\"vi_test.pos\", header = None )\n",
    "vi_test.columns = ['test_tag_words']\n",
    " \n",
    "vi_test_tagged_words = [pair.split() for pair in vi_test['test_tag_words']]\n",
    "test_set = []\n",
    "for index in vi_test_tagged_words:\n",
    "    data = [tuple(i.split('/')) for i  in index]\n",
    "    test_set.append(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viterbi Algorithm Accuracy:  94.33198380566802\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)      #define a random seed to get same sentences when run multiple times\n",
    " \n",
    "# choose random 10 numbers\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(10)]\n",
    "\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "tagged_seq = viterbiAlgorithm(test_tagged_words)\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    " \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dù', 'C'), ('khá', 'R'), ('đắt', 'A'), ('nhưng', 'C'), ('tôi', 'P'), ('vẫn', 'R'), ('đồng', 'N'), ('ý', 'N'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "test_sent=\"Dù khá đắt nhưng tôi vẫn đồng ý .\"\n",
    "pred_tags_rule=viterbiAlgorithm(test_sent.split())\n",
    "print(pred_tags_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
